{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### %run ../Tipping/Group\\ ARD.ipynb\n",
    "\n",
    "### CHANGED STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GroupARD(X, Y, w, in_group = 1, alpha_max = 100, max_iterations = 1000, M_zero = \"unknown\"):\n",
    "\n",
    "    N = len(X)\n",
    "    M = len(X[0])\n",
    "    \n",
    "    a = np.repeat(1.0, M) # alphas\n",
    "    b = 1.0               # Beta = 1/sig^2 \n",
    "\n",
    "    X1 = X\n",
    "\n",
    "    deletions = []\n",
    "    old_alphas = [a]\n",
    "\n",
    "    for ard_iteration in range(max_iterations):\n",
    "\n",
    "        # Sigma = (b*XTX + A)^-1\n",
    "        Sigma = np.linalg.inv(b*np.dot(X1.T,X1) + np.diag(a))\n",
    "\n",
    "        # mu = b*Sigma*X.T*Y\n",
    "        mu = b*np.dot(np.dot(Sigma, X1.T), Y)\n",
    "\n",
    "        gamma = 1.0 - a*np.diag(Sigma)\n",
    "        group_gamma = np.array([np.sum(gamma[i:i+in_group]) for i in range(0, len(gamma), in_group)])\n",
    "        mu_squared = mu**2\n",
    "        group_mu = np.array([np.sum(mu_squared[i:i+in_group]) for i in range(0, len(mu_squared), in_group)])\n",
    "        a_new = group_gamma/group_mu\n",
    "\n",
    "        error = np.sum((Y - np.dot(X1, mu))**2)\n",
    "        b_new = (N - np.sum(gamma))/error\n",
    "\n",
    "        a = [alpha for alpha in a_new for k in range(in_group)]\n",
    "        b = b_new\n",
    "\n",
    "        print(\"\\nIteration: \", ard_iteration, \" beta = \", b, \" Squared-Error = \", error)  \n",
    "\n",
    "        over = [i for i in range(len(a))if a[i] > alpha_max]\n",
    "        if over:\n",
    "            print(\"Deletions: \", len(over))\n",
    "            deletions = [over] + deletions\n",
    "            X1 = np.delete(X1,over,axis=1)\n",
    "            a = np.delete(a,over)\n",
    "        else:\n",
    "            a_converge = np.sum((a - np.array(old_alphas[-1]))**2)\n",
    "            print(\"Alpha distance = \", a_converge, \"   Max alpha = \", np.max(a))\n",
    "            if a_converge < .00001:\n",
    "                break\n",
    "        old_alphas.append(a)\n",
    "\n",
    "\n",
    "    # Recover mu\n",
    "    for i in deletions:\n",
    "        for j in i:\n",
    "            a = np.insert(a,j,-1)\n",
    "            mu = np.insert(mu,j,0)\n",
    "\n",
    "    df = pd.DataFrame(list(zip(a, mu, w)), columns = ['alpha', 'mu', 'w'])\n",
    "    print(\"\\n\", df)\n",
    "    print(\"\\nDeletions:\", np.sum([len(i) for i in deletions])/in_group, \"out of \", M_zero)\n",
    "    \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Initialize values\n",
    "t_max = 250      # length of the simulation\n",
    "num_neurons = 5  # number of neurons being simulated\n",
    "num_timelag = 5  # number of time steps back in time are weighted \n",
    "sigma = 0.005       # Choose sigma value for the Gaussian noise\n",
    "\n",
    "# initialize activity of all neurons to 1.0 for first 'num_timelag' time steps \n",
    "# (could use random start instead of 1)\n",
    "activity = np.ones((num_neurons, num_timelag))\n",
    "# activity = np.random.uniform(0,1,(num_neurons, num_timelag))\n",
    "\n",
    "# make space for future activity data, 't_max' time steps all initialized to 0\n",
    "activity = np.hstack((activity, np.zeros((num_neurons, t_max))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def add_ring(size, diag_dists, diag_vals): # size = N neurons, diag_indexs = array of diagonal indices\n",
    "#     a = np.zeros((size,size))\n",
    "#     for dist, val in zip(diag_dists, diag_vals):\n",
    "#         if 2*dist > size: # Also watch out for overlapping dists, e.g. 2 and 4 or 3 and 6, etc.\n",
    "#             print(\"Diagonal value \" + dist + \" is too big\")\n",
    "#             return -1\n",
    "#         for j in range(size):\n",
    "#             a[j][(j+dist)%size] = val\n",
    "#             a[(j+dist)%size][j] = val\n",
    "#     return a\n",
    "\n",
    "# def add_timelag(m, num_timelag, decay): # m is 2D array from add_diag, num_timelag is depth dimension\n",
    "#     a = m\n",
    "#     for i in range(num_timelag)[1:]:\n",
    "#         a = np.dstack((a,m*decay**i))\n",
    "#     return a\n",
    "\n",
    "# weights = add_ring(num_neurons, [0,1,2], [0.4,0.2,-.6])\n",
    "# weights = add_timelag(weights, num_timelag, 0.4)\n",
    "\n",
    "# activity[1:,num_timelag-1] = 0\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "### PICK RING ABOVE OR RANDOM BELOW\n",
    "################################################################\n",
    "\n",
    "### Pick weights, normally distributed\n",
    "weights = np.random.normal(0,1.0,(num_neurons, num_neurons, num_timelag))/(num_neurons*num_timelag)\n",
    "\n",
    "## Modify 'weights' such that individual neruons get 90% of the activity they had at the previous timestep\n",
    "## while the rest of their own history is weighted at 0\n",
    "for i in range(num_neurons):\n",
    "    #weights[i][i] = 0.0\n",
    "    weights[i][(i+1)%num_neurons] = 0.0\n",
    "    weights[i][i][-1] = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Simulate neuron activity data, update 'activity'\n",
    "for t in range(t_max):\n",
    "    for i in range(num_neurons):\n",
    "        \n",
    "        activity_ti = np.ravel(activity[:,t:t+num_timelag]) @ np.ravel(weights[i])\n",
    "        activity_ti += 0 if sigma <= 0 else np.random.normal(0,sigma) # Add Gaussian noise\n",
    "        activity[i,t+num_timelag] = activity_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Formulate M, a matrix of the relevant activities of each neuron at every time point\n",
    "m = np.zeros((t_max, num_neurons*num_timelag))\n",
    "for i in range(t_max):\n",
    "    for j in range(num_neurons):\n",
    "        m[i][j*num_timelag:(j+1)*num_timelag] = activity[j,i:i+num_timelag]\n",
    "        \n",
    "### Redefine actvity to ignore first 'num_timelag' steps of initialized activity\n",
    "new_activity = activity[:,num_timelag:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Visualize the actual activity and recovered activity of a neuron\n",
    "neuron_n = [0,1] # List of neurons to be observed\n",
    "weights = np.reshape(weights, (num_neurons,num_neurons*num_timelag), order = 'C').T\n",
    "\n",
    "f ,ax = plt.subplots(len(neuron_n),3, figsize=(15,5*len(neuron_n)))\n",
    "for i,j in enumerate(neuron_n):\n",
    "    ax[i][0].plot(new_activity.T[j]) # Actual activity\n",
    "    ax[i][1].plot((m @ weights).T[j]) # Recovered Activity Using Real Weights\n",
    "    ax[i][2].plot((m @ weights).T[j] - new_activity.T[j]) # Error\n",
    "    ax[i][0].set_ylabel(r'Neuron ' + str(i))\n",
    "    \n",
    "for axis, title in zip(ax[0], [r'Actual Activity', r'Recovered Activity w/ Real Weights', r'Error']):\n",
    "    axis.set_title(title)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Calculate best estimate of weights using maximum likelihood\n",
    "### IMPORTANT: We caclulate the pseudoinverse directly instead of doing \" inv(m.T @ m) @ m.T \"\n",
    "### For some reason this gives good answers, presumably problems with inverse stability screw up the other way\n",
    "w_est = np.linalg.solve(m.T @ m , m.T @ new_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualize the actual activity and recovered activity of a neuron\n",
    "neuron_n = [0,1]  # List of neurons to be observed\n",
    "\n",
    "f2 ,ax2 = plt.subplots(len(neuron_n),3, figsize=(15,5*len(neuron_n)))\n",
    "for i,j in enumerate(neuron_n):\n",
    "    ax2[i][0].plot(new_activity.T[j]) # Actual activity\n",
    "    ax2[i][1].plot((m @ w_est).T[j]) # Recovered Activity using Estimated Weights\n",
    "    ax2[i][2].plot((m @ w_est).T[j] - new_activity.T[j]) # Error\n",
    "    ax2[i][0].set_ylabel(r'Neuron ' + str(i))\n",
    "    \n",
    "for axis, title in zip(ax2[0], [r'Actual Activity', r'Recovered Activity w/ Estimated Weights', r'Error']):\n",
    "    axis.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = GroupARD(m, new_activity[:,0], weights[:,0], alpha_max=1000000, in_group=num_timelag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(m), np.shape(new_activity[:,0]), np.shape(weights[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "ax = f.add_subplot(111)\n",
    "\n",
    "plt.scatter(np.arange(0.5,25.5,1),weights[:,0], color = 'blue', label='Actual Weights')\n",
    "plt.scatter(np.arange(0.5,25.5,1),w_est[:,0], color = 'green', label='Linear Regression')\n",
    "plt.scatter(np.arange(0.5,25.5,1),mu, color = 'red', label='Group ARD')\n",
    "plt.xlim([0,25])\n",
    "plt.ylim([-0.2,1])\n",
    "plt.ylabel(r'Weight')\n",
    "plt.xlabel(r'Source of Connections')\n",
    "plt.title(r'Neuron 1 Connection Weights')\n",
    "plt.legend()\n",
    "\n",
    "for i in np.arange(5,25,5):\n",
    "    plt.axvline(x=i, linewidth=2, color='gray')\n",
    "    \n",
    "ax.set_xticks([2.5,7.5,12.5,17.5,22.5])\n",
    "ax.set_xticklabels(['Neuron 1','Neuron 2','Neuron 3','Neuron 4','Neuron 5',])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
